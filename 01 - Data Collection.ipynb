{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import timezone\n",
    "import time\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=\"1oGfKGDZWExJcQ\",\n",
    "                     client_secret=\"AkZ0bCrq71-VovJBpmIT84DSSlg\",\n",
    "                     password = '',\n",
    "                     user_agent=\"suggestions_collecter_calste\",\n",
    "                     username=\"calste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "url_com = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "#res = requests.get(url, params = {'size' : 5, 'subreddit' : 'askreddit'})\n",
    "#res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function created for Project 3, modified for better functionality and capstone project needs\n",
    "\n",
    "def get_sub_df(sub_name, num_to_pull, start_utc = None, min_comments = 0, drop_removed = True):\n",
    "    #Returns a dataframe containing num_to_pull submissions from the specified subreddit\n",
    "    #Dataframe has ID, Title, selftext and num_comments\n",
    "    \n",
    "    post_count = 0    #Keeps track of how many posts have been pulled\n",
    "    data = []         #Holds all the data to create the DF after the while loop\n",
    "    \n",
    "    res_count = 0     #for debugging\n",
    "    \n",
    "    if start_utc == None:\n",
    "        start_utc = int(datetime.now(timezone.utc).timestamp()) #If the start timestamp isn't specified, use the current time\n",
    "        \n",
    "    min_comment_count = '>' + str(min_comments-1) #paramater to select only submissions with comments greater than the number specified\n",
    "    \n",
    "    timer = 0 \n",
    "    \n",
    "    while post_count < num_to_pull:\n",
    "        #To make sure to get the specific number pulled, check to see if the remaining count is less than 100, if not, just get 100\n",
    "        if (num_to_pull - post_count) < 200:\n",
    "            get_size = (num_to_pull - post_count)\n",
    "        else:\n",
    "            get_size = 200\n",
    "            \n",
    "        timer = time.time() #Timer to avoid 429 codes from making too many requests\n",
    "        \n",
    "        print(\"get submissions\")\n",
    "        \n",
    "        clear_output(wait=True) #reference: https://stackoverflow.com/a/24818304\n",
    "        \n",
    "        res = requests.get(url, params = {'subreddit' : sub_name, 'size' : get_size, 'before' : start_utc, 'num_comments' : min_comment_count})\n",
    "        res_count += 1\n",
    "        \n",
    "        print(f'{100 * post_count/num_to_pull}%')\n",
    "        \n",
    "        # Wait for ONE second, but in 0.1s increments (saves time because the request may have taken >0.1s)\n",
    "        # This shouldn't ever come close to exceeding the limit of 200 requests/minute\n",
    "        \n",
    "        \n",
    "        \n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(.1)\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            print(f'Status Code: {res.status_code}')\n",
    "            print(res_count)\n",
    "            return None\n",
    "            \n",
    "        new_data = res.json()['data']\n",
    "            \n",
    "        data.extend(new_data)\n",
    "        \n",
    "        post_count += 200 #not a problem to go over num_to_pull\n",
    "        \n",
    "        print(\"get new utc\")\n",
    "        \n",
    "        if post_count < num_to_pull:\n",
    "            try:\n",
    "                #This is the starting point for grabbing more posts\n",
    "                start_utc = new_data[-1]['created_utc']\n",
    "            except:\n",
    "                #If that doesn't work, try to find out what went wrong:\n",
    "                print(\"Failed to get UTC of last Post. Printing list element that caused failure.\")\n",
    "                try:\n",
    "                    post_count = num_to_pull\n",
    "                    print(new_data[-1])\n",
    "                    break\n",
    "                except:\n",
    "                    print(\"Printing last list element failed.\")\n",
    "                    break\n",
    "    \n",
    "    print(res_count)\n",
    "    \n",
    "    columns_for_df = ['id', 'title', 'selftext', 'removed_by_category', 'created_utc', 'num_comments', 'link_flair_css_class']\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    #select the columns, but only if they exist in the dataframe - the res won't return data when there are 0 non-null values\n",
    "    df = df[df.columns & columns_for_df]\n",
    "    \n",
    "    #Filter out submissions that have been removed. Could result in small samples for heavily moderated forums, so there is the option to keep them in.\n",
    "    if drop_removed and 'removed_by_category' in df.columns:\n",
    "        df = df[df['removed_by_category'].isna()]\n",
    "    \n",
    "    #Drop this column, it is no longer needed\n",
    "    if 'removed_by_category' in df.columns:\n",
    "        df.drop(columns = 'removed_by_category', inplace = True)\n",
    "    \n",
    "    #Convert timestamps to datetimes\n",
    "    #df['created_utc'] = df['created_utc'].apply(datetime.fromtimestamp)    \n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_comments(df):\n",
    "    #function to get dictionary from json data - using submission id numbers from the passed dataframe\n",
    "    #This function should work on any size df*, but may take a looong time if there are a lot of comments to get \n",
    "    # - if new comments are being made on the submissions, this function might not get all the comments\n",
    "    #  * unless there is a limit in the API on how many ids can be passed\n",
    "    \n",
    "    #First, get a list of id's from submissions in the dataframe: \n",
    "    \n",
    "    id_string = ''\n",
    "    \n",
    "    for i in df['id']:\n",
    "        id_string += i + ', ' #needs to be formated like: 'id1234, id1235, id1236'\n",
    "        \n",
    "    id_string = id_string[:-2] #drop the last ', '\n",
    "    \n",
    "    #Get the first batch of data and create the list that will ultimately be returned\n",
    "    com_res = requests.get(url_com, params = {'link_id' : id_string, 'size' : 500})\n",
    "    com_data = com_res.json()['data']\n",
    "    \n",
    "    #Check to make sure that the request worked:\n",
    "    if com_res.status_code != 200:\n",
    "        print(f'Status code: {com_res.status_code}')\n",
    "        return None\n",
    "    \n",
    "    #This is the goal - the number of comments we want to end up with (ideally)\n",
    "    num_comments = df['num_comments'].sum()\n",
    "    \n",
    "    if(num_comments <= 500):\n",
    "        return com_data\n",
    "    \n",
    "    last_length = -1\n",
    "    comment_count = 0\n",
    "    timer = 0\n",
    "    \n",
    "    res_counter = 0\n",
    "    \n",
    "    # Handling the case when there are no comments to get:\n",
    "    if len(com_data) == 0:\n",
    "        return com_data\n",
    "    \n",
    "    while (len(com_data) < num_comments) & (last_length != len(com_data)):\n",
    "        #This makes sure that the while loop doesn't continue forever if something goes wrong\n",
    "        last_length = len(com_data)\n",
    "        \n",
    "        try:\n",
    "            #This is the starting point for grabbing more comments\n",
    "            last_comment_utc = com_data[-1]['created_utc'] \n",
    "        except:\n",
    "            print(\"Failed to get UTC of last comment. Printing list element that caused failure.\")\n",
    "            print(com_data[-1])\n",
    "        \n",
    "        timer = time.time()\n",
    "        \n",
    "        new_res = requests.get(url_com, params = {'link_id' : id_string,\n",
    "                                                  'size' : 500,\n",
    "                                                  'before' : last_comment_utc,\n",
    "                                                  'limit' : 500})\n",
    "        \n",
    "        res_counter += 1\n",
    "        \n",
    "        comment_count += 500\n",
    "        \n",
    "        print(f'{100 * comment_count/num_comments}%')\n",
    "        \n",
    "        \n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if new_res.status_code == 200:\n",
    "            \n",
    "            new_data = new_res.json()['data']\n",
    "            \n",
    "            for new_comment in new_data:\n",
    "                com_data.append(new_comment)\n",
    "                \n",
    "        else:\n",
    "            print(f'Problem when pulling new comments: Code {new_res.status_code}')\n",
    "            \n",
    "    print(res_counter)\n",
    "            \n",
    "    return com_data\n",
    "\n",
    "def assign_comments(com_data, df):\n",
    "    #Take comment data ( .json()['data'] ) and make a new column for the dataframe with the comment texts\n",
    "    \n",
    "    df_c = df.copy() #make a copy of the df, just to be safe/explicit. This copy is what is returned by the function.\n",
    "\n",
    "    #Make a zip opject with submission ids and comment text\n",
    "    com_zip = zip([com_data[i]['link_id'][-6:] for i in range(len(com_data))], [com_data[i]['body'] for i in range(len(com_data))])\n",
    "\n",
    "    # create a list of empty lists and make that list the new column\n",
    "    df_c['comments'] = [[] for _ in range(len(df_c))]\n",
    "    \n",
    "    # how many comments are assigned to each row in the dataframe\n",
    "    assignments = np.zeros_like(df_c['num_comments'])\n",
    "\n",
    "    #List of ids, to check if the comment's submission id is in the dataframe\n",
    "    id_list = df_c['id'].values\n",
    "\n",
    "    #counts the total number of comments that can't be assigned to a row\n",
    "    unassigned = 0\n",
    "\n",
    "    #Loop through the zip object, appending comments to the correct row on the 'comments' columns created above, then add 1 to assignment list (to be column later)\n",
    "    for idx, com in com_zip:\n",
    "        if idx in id_list:\n",
    "            df_c[df_c['id'] == idx]['comments'].item().append(com)\n",
    "            assignments[df_c[df_c['id'] == idx].index.item()] += 1\n",
    "        else:\n",
    "            unassigned += 1\n",
    "\n",
    "    if(unassigned > 0):\n",
    "        print(f'There are {unassigned} comments that could not be assigned to a submission!')\n",
    "    \n",
    "    df_c['assigned_comments'] = assignments\n",
    "    \n",
    "    return df_c\n",
    "\n",
    "def get_and_assign_comments(df):\n",
    "    #This function grabs comments in chunks and assigns them to the submissions\n",
    "    #\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    comment_data = []\n",
    "    \n",
    "    total_length = df_copy.shape[0]\n",
    "    \n",
    "    chunk = 0\n",
    "    chunk_size = 25\n",
    "    \n",
    "    while chunk * chunk_size < total_length:\n",
    "        start_row = chunk * chunk_size\n",
    "        end_row = (chunk + 1) * chunk_size\n",
    "        \n",
    "        if end_row < total_length:\n",
    "            comment_data += get_comments(df_copy[start_row : end_row + 1])\n",
    "        else:\n",
    "            comment_data += get_comments(df_copy[start_row :])\n",
    "            \n",
    "        chunk += 1\n",
    "    \n",
    "    df_copy = assign_comments(comment_data, df_copy)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def get_titles_text(sub_name, number = 10_000, start_time = None):\n",
    "    if sub_name + '_data.csv' in os.listdir('./data'):\n",
    "        print(f\"That data ({sub_name}) is already in the data folder. Delete the file if you want to get the data again.\")\n",
    "        return None\n",
    "    else:\n",
    "        df = get_sub_df(sub_name, number, start_utc = start_time)\n",
    "        df.to_csv('./data/' + sub_name + '_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now(timezone.utc)\n",
    "yesterday = today - timedelta(days = 1)\n",
    "yesterday_timestamp = int(datetime.timestamp(yesterday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_titles_text('moviesuggestions', number = 30000, start_time = yesterday_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_sub_df('moviesuggestions', num_to_pull = 30_000, start_utc= yesterday_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_df = get_sub_df('moviesuggestions', num_to_pull = 100, start_utc= yesterday_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(\"data/slow_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_utc = base_df[-1:]['created_utc'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1600961198</td>\n",
       "      <td>iyzb2g</td>\n",
       "      <td>request</td>\n",
       "      <td>6</td>\n",
       "      <td>Not asking for something very deep or slow pac...</td>\n",
       "      <td>Gay romantic film with an engaging plot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1600960931</td>\n",
       "      <td>iyz81n</td>\n",
       "      <td>request</td>\n",
       "      <td>15</td>\n",
       "      <td>Need to fill up My List!  I enjoy edge of your...</td>\n",
       "      <td>FIRST TIME HAVING NETLIX!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1600960479</td>\n",
       "      <td>iyz3e7</td>\n",
       "      <td>request</td>\n",
       "      <td>16</td>\n",
       "      <td>basically I want a fun movie to kill time with...</td>\n",
       "      <td>Movies where main characters are or become cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1600959529</td>\n",
       "      <td>iyyt03</td>\n",
       "      <td>request</td>\n",
       "      <td>9</td>\n",
       "      <td>Hey! I am looking for movie recommendations wh...</td>\n",
       "      <td>Looking for movies which are fun and not too s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1600958640</td>\n",
       "      <td>iyyjk1</td>\n",
       "      <td>request</td>\n",
       "      <td>12</td>\n",
       "      <td>Looking for all the sherlock holmes movies and...</td>\n",
       "      <td>All sherlock holmes movies and tv shows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>76</td>\n",
       "      <td>1562551304</td>\n",
       "      <td>caf2dg</td>\n",
       "      <td>request</td>\n",
       "      <td>12</td>\n",
       "      <td>Doesn’t have to have a stellar cast like spotl...</td>\n",
       "      <td>A movie like “Spotlight” (2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>78</td>\n",
       "      <td>1562550412</td>\n",
       "      <td>caewxz</td>\n",
       "      <td>request</td>\n",
       "      <td>7</td>\n",
       "      <td>I'm so sick of every main character being obse...</td>\n",
       "      <td>Movies or TV shows in which the character reje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>84</td>\n",
       "      <td>1562541042</td>\n",
       "      <td>cadciq</td>\n",
       "      <td>request</td>\n",
       "      <td>24</td>\n",
       "      <td>First time posting here. I'm curious if there ...</td>\n",
       "      <td>Movies that depict a futuristic society that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>93</td>\n",
       "      <td>1562526176</td>\n",
       "      <td>caaiho</td>\n",
       "      <td>request</td>\n",
       "      <td>32</td>\n",
       "      <td>Something that is nicely made. Good actors, no...</td>\n",
       "      <td>Funny action movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>0</td>\n",
       "      <td>1562516384</td>\n",
       "      <td>ca8l2j</td>\n",
       "      <td>request</td>\n",
       "      <td>6</td>\n",
       "      <td>Hoping to find films with rebellious character...</td>\n",
       "      <td>The best on-screen rebels?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11329 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  created_utc      id link_flair_css_class  num_comments  \\\n",
       "0          0   1600961198  iyzb2g              request             6   \n",
       "1          1   1600960931  iyz81n              request            15   \n",
       "2          2   1600960479  iyz3e7              request            16   \n",
       "3          3   1600959529  iyyt03              request             9   \n",
       "4          4   1600958640  iyyjk1              request            12   \n",
       "...      ...          ...     ...                  ...           ...   \n",
       "19303     76   1562551304  caf2dg              request            12   \n",
       "19305     78   1562550412  caewxz              request             7   \n",
       "19311     84   1562541042  cadciq              request            24   \n",
       "19320     93   1562526176  caaiho              request            32   \n",
       "19327      0   1562516384  ca8l2j              request             6   \n",
       "\n",
       "                                                selftext  \\\n",
       "0      Not asking for something very deep or slow pac...   \n",
       "1      Need to fill up My List!  I enjoy edge of your...   \n",
       "2      basically I want a fun movie to kill time with...   \n",
       "3      Hey! I am looking for movie recommendations wh...   \n",
       "4      Looking for all the sherlock holmes movies and...   \n",
       "...                                                  ...   \n",
       "19303  Doesn’t have to have a stellar cast like spotl...   \n",
       "19305  I'm so sick of every main character being obse...   \n",
       "19311  First time posting here. I'm curious if there ...   \n",
       "19320  Something that is nicely made. Good actors, no...   \n",
       "19327  Hoping to find films with rebellious character...   \n",
       "\n",
       "                                                   title  \n",
       "0               Gay romantic film with an engaging plot.  \n",
       "1                              FIRST TIME HAVING NETLIX!  \n",
       "2      Movies where main characters are or become cri...  \n",
       "3      Looking for movies which are fun and not too s...  \n",
       "4                All sherlock holmes movies and tv shows  \n",
       "...                                                  ...  \n",
       "19303                    A movie like “Spotlight” (2015)  \n",
       "19305  Movies or TV shows in which the character reje...  \n",
       "19311  Movies that depict a futuristic society that i...  \n",
       "19320                                Funny action movie.  \n",
       "19327                         The best on-screen rebels?  \n",
       "\n",
       "[11329 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_df = base_df[base_df['link_flair_css_class'] == 'request'].copy()\n",
    "req_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.47365169035219 %\n"
     ]
    }
   ],
   "source": [
    "comm_df = pd.read_csv('data/slow_comments.csv')\n",
    "saved_comments_post_ids = list(pd.read_csv('data/saved_comments_list.csv')['0'])\n",
    "posts_to_get_comments = [title_id for title_id in req_df['id'] if title_id not in saved_comments_post_ids]\n",
    "df_start = req_df.shape[0] - len(posts_to_get_comments)\n",
    "\n",
    "comm_df = comm_df[['author', 'score', 'body', 'stickied', 'created_utc', 'id', 'parent_id', 'link_id', 'is_submitter']]\n",
    "\n",
    "df_start = 0\n",
    "\n",
    "for x in range(int(len(posts_to_get_comments) / 25)):\n",
    "    temp_df = req_df[df_start : df_start + 25]\n",
    "    com_data = get_comments(temp_df)\n",
    "    comm_df = comm_df.append(pd.DataFrame(com_data)[['author', 'score', 'body', 'stickied', 'created_utc', 'id', 'parent_id', 'link_id', 'is_submitter']])\n",
    "    df_start += 10\n",
    "    saved_comments_post_ids.extend(temp_df['id'])\n",
    "    comm_df.to_csv('data/slow_comments.csv', index = False)\n",
    "    pd.DataFrame(saved_comments_post_ids).to_csv('data/saved_comments_list.csv', index = False)\n",
    "    \n",
    "    timer = time.time()\n",
    "    clear_output(wait=True)\n",
    "    print(len(saved_comments_post_ids) / req_df.shape[0] * 100, '%')\n",
    "    time.sleep(3)\n",
    "\n",
    "#lite_cdf = comm_df[['author', 'score', 'body', 'stickied', 'created_utc', 'id', 'parent_id', 'link_id', 'is_submitter']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(int( (30_000 - base_df.shape[0]) / 100 )):\n",
    "    start_time = base_df[-1:]['created_utc'].values[0]\n",
    "    base_df = base_df.append(get_sub_df('moviesuggestions', num_to_pull=100, start_utc = start_time))\n",
    "    print(len(base_df))\n",
    "    \n",
    "    base_df.to_csv(\"data/slow_df.csv\", index = False)\n",
    "    \n",
    "    print(\"wait...\")\n",
    "    wait_time = 10\n",
    "    timer = time.time()\n",
    "    for x in range(int(wait_time / 5)):\n",
    "        print(wait_time - x*5, end = '')\n",
    "        while(time.time() < (timer + 5*x)):\n",
    "            print('.', end = '')\n",
    "            time.sleep(1)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./data/moviesuggestions_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com_data = get_comments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More work:\n",
    "\n",
    "Currently the csv has all the comments in a single cell.\n",
    "\n",
    "This is a problem because they are saved as one long string, and without any data such as author, score, nest level, etc., which will likely be important as this project goes on. (such as removing negative-score comments from consideration, or collecting data from helpful bots)\n",
    "\n",
    "I will need to create a new database for comments and use that alongside the title/text data. Keeping them together in the same csv won't work for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = pd.DataFrame(com_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_cdf = comm_df[['author', 'score', 'body', 'stickied', 'created_utc', 'id', 'parent_id', 'link_id', 'is_submitter']]\n",
    "lite_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_cdf[lite_cdf['parent_id'] != lite_cdf['link_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_cdf.to_csv('./movies_data/comments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
