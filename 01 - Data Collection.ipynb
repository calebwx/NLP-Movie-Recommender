{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import timezone\n",
    "import time\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "url_com = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "res = requests.get(url, params = {'subreddit' : 'moviesuggestions'})\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function created for Project 3, modified for better functionality and capstone project needs\n",
    "\n",
    "def get_sub_df(sub_name, num_to_pull, start_utc = None, min_comments = 0, drop_removed = True):\n",
    "    #Returns a dataframe containing num_to_pull submissions from the specified subreddit\n",
    "    #Dataframe has ID, Title, selftext and num_comments\n",
    "    \n",
    "    post_count = 0    #Keeps track of how many posts have been pulled\n",
    "    data = []         #Holds all the data to create the DF after the while loop\n",
    "    \n",
    "    res_count = 0     #for debugging\n",
    "    \n",
    "    if start_utc == None:\n",
    "        start_utc = int(datetime.now(timezone.utc).timestamp()) #If the start timestamp isn't specified, use the current time\n",
    "        \n",
    "    min_comment_count = '>' + str(min_comments-1) #paramater to select only submissions with comments greater than the number specified\n",
    "    \n",
    "    timer = 0 \n",
    "    \n",
    "    while post_count < num_to_pull:\n",
    "        #To make sure to get the specific number pulled, check to see if the remaining count is less than 100, if not, just get 100\n",
    "        if (num_to_pull - post_count) < 100:\n",
    "            get_size = (num_to_pull - post_count)\n",
    "        else:\n",
    "            get_size = 100\n",
    "            \n",
    "        timer = time.time() #Timer to avoid 429 codes from making too many requests\n",
    "        \n",
    "        res = requests.get(url, params = {'subreddit' : sub_name, 'size' : get_size, 'before' : start_utc, 'num_comments' : min_comment_count})\n",
    "        res_count += 1\n",
    "        \n",
    "        clear_output(wait=True) #reference: https://stackoverflow.com/a/24818304\n",
    "        \n",
    "        print(f'{100 * post_count/num_to_pull}%')\n",
    "        \n",
    "        # Wait for ONE second, but in 0.1s increments (saves time because the request may have taken >0.1s)\n",
    "        # This shouldn't ever come close to exceeding the limit of 200 requests/minute\n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            print(f'Status Code: {res.status_code}')\n",
    "            print(res_count)\n",
    "            return None\n",
    "            \n",
    "        new_data = res.json()['data']\n",
    "            \n",
    "        data.extend(new_data)\n",
    "        \n",
    "        post_count += 100 #not a problem to go over num_to_pull\n",
    "        \n",
    "        if post_count < num_to_pull:\n",
    "            try:\n",
    "                #This is the starting point for grabbing more posts\n",
    "                start_utc = new_data[-1]['created_utc']\n",
    "            except:\n",
    "                #If that doesn't work, try to find out what went wrong:\n",
    "                print(\"Failed to get UTC of last Post. Printing list element that caused failure.\")\n",
    "                try:\n",
    "                    post_count = num_to_pull\n",
    "                    print(new_data[-1])\n",
    "                except:\n",
    "                    print(\"Printing last list element failed.\")\n",
    "    \n",
    "    print(res_count)\n",
    "    \n",
    "    columns_for_df = ['id', 'title', 'selftext', 'removed_by_category', 'created_utc', 'num_comments', 'link_flair_css_class']\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    #select the columns, but only if they exist in the dataframe - the res won't return data when there are 0 non-null values\n",
    "    df = df[df.columns & columns_for_df]\n",
    "    \n",
    "    #Filter out submissions that have been removed. Could result in small samples for heavily moderated forums, so there is the option to keep them in.\n",
    "    if drop_removed and 'removed_by_category' in df.columns:\n",
    "        df = df[df['removed_by_category'].isna()]\n",
    "    \n",
    "    #Drop this column, it is no longer needed\n",
    "    if 'removed_by_category' in df.columns:\n",
    "        df.drop(columns = 'removed_by_category', inplace = True)\n",
    "    \n",
    "    #Convert timestamps to datetimes\n",
    "    df['created_utc'] = df['created_utc'].apply(datetime.fromtimestamp)    \n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(df):\n",
    "    #function to get dictionary from json data - using submission id numbers from the passed dataframe\n",
    "    #This function should work on any size df*, but may take a looong time if there are a lot of comments to get \n",
    "    # - if new comments are being made on the submissions, this function might not get all the comments\n",
    "    #  * unless there is a limit in the API on how many ids can be passed\n",
    "    \n",
    "    #First, get a list of id's from submissions in the dataframe: \n",
    "    \n",
    "    id_string = ''\n",
    "    \n",
    "    for i in df['id']:\n",
    "        id_string += i + ', ' #needs to be formated like: 'id1234, id1235, id1236'\n",
    "        \n",
    "    id_string = id_string[:-2] #drop the last ', '\n",
    "    \n",
    "    #Get the first batch of data and create the list that will ultimately be returned\n",
    "    com_res = requests.get(url_com, params = {'link_id' : id_string, 'size' : 500})\n",
    "    com_data = com_res.json()['data']\n",
    "    \n",
    "    #Check to make sure that the request worked:\n",
    "    if com_res.status_code != 200:\n",
    "        print(f'Status code: {com_res.status_code}')\n",
    "        return None\n",
    "    \n",
    "    #This is the goal - the number of comments we want to end up with (ideally)\n",
    "    num_comments = df['num_comments'].sum()\n",
    "    \n",
    "    if(num_comments <= 500):\n",
    "        return com_data\n",
    "    \n",
    "    last_length = -1\n",
    "    comment_count = 0\n",
    "    timer = 0\n",
    "    \n",
    "    res_counter = 0\n",
    "    \n",
    "    # Handling the case when there are no comments to get:\n",
    "    if len(com_data) == 0:\n",
    "        return com_data\n",
    "    \n",
    "    while (len(com_data) < num_comments) & (last_length != len(com_data)):\n",
    "        #This makes sure that the while loop doesn't continue forever if something goes wrong\n",
    "        last_length = len(com_data)\n",
    "        \n",
    "        try:\n",
    "            #This is the starting point for grabbing more comments\n",
    "            last_comment_utc = com_data[-1]['created_utc'] \n",
    "        except:\n",
    "            print(\"Failed to get UTC of last comment. Printing list element that caused failure.\")\n",
    "            print(com_data[-1])\n",
    "        \n",
    "        timer = time.time()\n",
    "        \n",
    "        new_res = requests.get(url_com, params = {'link_id' : id_string,\n",
    "                                                  'size' : 500,\n",
    "                                                  'before' : last_comment_utc,\n",
    "                                                  'limit' : 500})\n",
    "        \n",
    "        res_counter += 1\n",
    "        \n",
    "        comment_count += 500\n",
    "        \n",
    "        print(f'{100 * comment_count/num_comments}%')\n",
    "        \n",
    "        \n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if new_res.status_code == 200:\n",
    "            \n",
    "            new_data = new_res.json()['data']\n",
    "            \n",
    "            for new_comment in new_data:\n",
    "                com_data.append(new_comment)\n",
    "                \n",
    "        else:\n",
    "            print(f'Problem when pulling new comments: Code {new_res.status_code}')\n",
    "            \n",
    "    print(res_counter)\n",
    "            \n",
    "    return com_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_comments(com_data, df):\n",
    "    #Take comment data ( .json()['data'] ) and make a new column for the dataframe with the comment texts\n",
    "    \n",
    "    df_c = df.copy() #make a copy of the df, just to be safe/explicit. This copy is what is returned by the function.\n",
    "\n",
    "    #Make a zip opject with submission ids and comment text\n",
    "    com_zip = zip([com_data[i]['link_id'][-6:] for i in range(len(com_data))], [com_data[i]['body'] for i in range(len(com_data))])\n",
    "\n",
    "    # create a list of empty lists and make that list the new column\n",
    "    df_c['comments'] = [[] for _ in range(len(df_c))]\n",
    "    \n",
    "    # how many comments are assigned to each row in the dataframe\n",
    "    assignments = np.zeros_like(df_c['num_comments'])\n",
    "\n",
    "    #List of ids, to check if the comment's submission id is in the dataframe\n",
    "    id_list = df_c['id'].values\n",
    "\n",
    "    #counts the total number of comments that can't be assigned to a row\n",
    "    unassigned = 0\n",
    "\n",
    "    #Loop through the zip object, appending comments to the correct row on the 'comments' columns created above, then add 1 to assignment list (to be column later)\n",
    "    for idx, com in com_zip:\n",
    "        if idx in id_list:\n",
    "            df_c[df_c['id'] == idx]['comments'].item().append(com)\n",
    "            assignments[df_c[df_c['id'] == idx].index.item()] += 1\n",
    "        else:\n",
    "            unassigned += 1\n",
    "\n",
    "    if(unassigned > 0):\n",
    "        print(f'There are {unassigned} comments that could not be assigned to a submission!')\n",
    "    \n",
    "    df_c['assigned_comments'] = assignments\n",
    "    \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_assign_comments(df):\n",
    "    #This function grabs comments in chunks and assigns them to the submissions\n",
    "    #\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    comment_data = []\n",
    "    \n",
    "    total_length = df_copy.shape[0]\n",
    "    \n",
    "    chunk = 0\n",
    "    chunk_size = 25\n",
    "    \n",
    "    while chunk * chunk_size < total_length:\n",
    "        start_row = chunk * chunk_size\n",
    "        end_row = (chunk + 1) * chunk_size\n",
    "        \n",
    "        if end_row < total_length:\n",
    "            comment_data += get_comments(df_copy[start_row : end_row + 1])\n",
    "        else:\n",
    "            comment_data += get_comments(df_copy[start_row :])\n",
    "            \n",
    "        chunk += 1\n",
    "    \n",
    "    df_copy = assign_comments(comment_data, df_copy)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_text(sub_name, number = 10_000, start_time = None):\n",
    "    if sub_name + '_data.csv' in os.listdir('./data'):\n",
    "        print(f\"That data ({sub_name}) is already in the data folder. Delete the file if you want to get the data again.\")\n",
    "        return None\n",
    "    else:\n",
    "        df = get_sub_df(sub_name, number, start_utc = start_time)\n",
    "        #df = get_and_assign_comments(df)\n",
    "        # -----> Will be moved to new DF and CSV, assignment will be handled differently\n",
    "        df.to_csv('./data/' + sub_name + '_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now(timezone.utc)\n",
    "yesterday = today - timedelta(days = 1)\n",
    "yesterday_timestamp = int(datetime.timestamp(yesterday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0%\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "get_titles_text('moviesuggestions', number = 500, start_time = yesterday_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/moviesuggestions_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.428625306430323%\n",
      "18.857250612860646%\n",
      "28.285875919290966%\n",
      "37.71450122572129%\n",
      "47.14312653215161%\n",
      "56.57175183858193%\n",
      "66.00037714501225%\n",
      "75.42900245144259%\n",
      "84.8576277578729%\n",
      "94.28625306430322%\n",
      "103.71487837073354%\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "com_data = get_comments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "request    0.820261\n",
       "suggest    0.179739\n",
       "Name: link_flair_css_class, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['link_flair_css_class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>248.848606</td>\n",
       "      <td>19.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>247.018182</td>\n",
       "      <td>9.327273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index  num_comments\n",
       "link_flair_css_class                          \n",
       "request               248.848606     19.003984\n",
       "suggest               247.018182      9.327273"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by = 'link_flair_css_class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'created_utc', 'id', 'link_flair_css_class', 'num_comments',\n",
       "       'selftext', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More work:\n",
    "\n",
    "Currently the csv has all the comments in a single cell.\n",
    "\n",
    "This is a problem because they are saved as one long string, and without any data such as author, score, nest level, etc., which will likely be important as this project goes on. (such as removing negative-score comments from consideration, or collecting data from helpful bots)\n",
    "\n",
    "I will need to create a new database for comments and use that alongside the title/text data. Keeping them together in the same csv won't work for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = pd.DataFrame(com_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'approved_at_utc', 'associated_award', 'author',\n",
       "       'author_flair_background_color', 'author_flair_css_class',\n",
       "       'author_flair_richtext', 'author_flair_template_id',\n",
       "       'author_flair_text', 'author_flair_text_color', 'author_flair_type',\n",
       "       'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders',\n",
       "       'banned_at_utc', 'body', 'can_mod_post', 'collapsed',\n",
       "       'collapsed_because_crowd_control', 'collapsed_reason', 'comment_type',\n",
       "       'created_utc', 'distinguished', 'edited', 'gildings', 'id',\n",
       "       'is_submitter', 'link_id', 'locked', 'no_follow', 'parent_id',\n",
       "       'permalink', 'retrieved_on', 'score', 'send_replies', 'stickied',\n",
       "       'subreddit', 'subreddit_id', 'top_awarded_type',\n",
       "       'total_awards_received', 'treatment_tags', 'author_cakeday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>stickied</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>is_submitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WI_089129</td>\n",
       "      <td>1</td>\n",
       "      <td>Cries and Whispers\\n\\nThe Godfather\\n\\nThe Tin...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600816141</td>\n",
       "      <td>g69iym4</td>\n",
       "      <td>t3_ixcr5j</td>\n",
       "      <td>t3_ixcr5j</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MrNovembr</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes Man with Jim Carrey is my number one \"inee...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600814352</td>\n",
       "      <td>g69fstl</td>\n",
       "      <td>t3_iwu11b</td>\n",
       "      <td>t3_iwu11b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Budgie2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Really excited to find this one--never heard o...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600809663</td>\n",
       "      <td>g696zi1</td>\n",
       "      <td>t1_g66cqnr</td>\n",
       "      <td>t3_ix7ua1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fahrenheitisretarded</td>\n",
       "      <td>1</td>\n",
       "      <td>Great suggestion. Forgot about that film entir...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600808248</td>\n",
       "      <td>g6946y3</td>\n",
       "      <td>t1_g66cqnr</td>\n",
       "      <td>t3_ix7ua1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexander_The_Based</td>\n",
       "      <td>1</td>\n",
       "      <td>gonna watch pirates band of misfits. i can't b...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600808239</td>\n",
       "      <td>g6946av</td>\n",
       "      <td>t1_g66xbjq</td>\n",
       "      <td>t3_iwlb0z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>georgieramone</td>\n",
       "      <td>5</td>\n",
       "      <td>Leaving Las Vegas</td>\n",
       "      <td>False</td>\n",
       "      <td>1599956307</td>\n",
       "      <td>g5087wr</td>\n",
       "      <td>t3_iro0jk</td>\n",
       "      <td>t3_iro0jk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>toxic_pantaloons</td>\n",
       "      <td>3</td>\n",
       "      <td>Event Horizon, maybe Sunshine\\n\\nETA: star tre...</td>\n",
       "      <td>False</td>\n",
       "      <td>1599956143</td>\n",
       "      <td>g507sg9</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>BluBrews</td>\n",
       "      <td>4</td>\n",
       "      <td>Primer, not about space but its good sci fi</td>\n",
       "      <td>False</td>\n",
       "      <td>1599955741</td>\n",
       "      <td>g506ikx</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>TB54</td>\n",
       "      <td>2</td>\n",
       "      <td>*Ad Astra* (Gray)\\n\\n*Mission to Mars* (DePalm...</td>\n",
       "      <td>False</td>\n",
       "      <td>1599955546</td>\n",
       "      <td>g5061yy</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>IdealBlueMan</td>\n",
       "      <td>3</td>\n",
       "      <td>Alien\\n\\nSolaris (either version)\\n\\nThe Abyss...</td>\n",
       "      <td>False</td>\n",
       "      <td>1599955330</td>\n",
       "      <td>g505ffz</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4804 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author  score  \\\n",
       "0                WI_089129      1   \n",
       "1                MrNovembr      1   \n",
       "2               Budgie2018      1   \n",
       "3     fahrenheitisretarded      1   \n",
       "4      Alexander_The_Based      1   \n",
       "...                    ...    ...   \n",
       "4799         georgieramone      5   \n",
       "4800      toxic_pantaloons      3   \n",
       "4801              BluBrews      4   \n",
       "4802                  TB54      2   \n",
       "4803          IdealBlueMan      3   \n",
       "\n",
       "                                                   body  stickied  \\\n",
       "0     Cries and Whispers\\n\\nThe Godfather\\n\\nThe Tin...     False   \n",
       "1     Yes Man with Jim Carrey is my number one \"inee...     False   \n",
       "2     Really excited to find this one--never heard o...     False   \n",
       "3     Great suggestion. Forgot about that film entir...     False   \n",
       "4     gonna watch pirates band of misfits. i can't b...     False   \n",
       "...                                                 ...       ...   \n",
       "4799                                  Leaving Las Vegas     False   \n",
       "4800  Event Horizon, maybe Sunshine\\n\\nETA: star tre...     False   \n",
       "4801        Primer, not about space but its good sci fi     False   \n",
       "4802  *Ad Astra* (Gray)\\n\\n*Mission to Mars* (DePalm...     False   \n",
       "4803  Alien\\n\\nSolaris (either version)\\n\\nThe Abyss...     False   \n",
       "\n",
       "      created_utc       id   parent_id    link_id  is_submitter  \n",
       "0      1600816141  g69iym4   t3_ixcr5j  t3_ixcr5j         False  \n",
       "1      1600814352  g69fstl   t3_iwu11b  t3_iwu11b         False  \n",
       "2      1600809663  g696zi1  t1_g66cqnr  t3_ix7ua1          True  \n",
       "3      1600808248  g6946y3  t1_g66cqnr  t3_ix7ua1         False  \n",
       "4      1600808239  g6946av  t1_g66xbjq  t3_iwlb0z          True  \n",
       "...           ...      ...         ...        ...           ...  \n",
       "4799   1599956307  g5087wr   t3_iro0jk  t3_iro0jk         False  \n",
       "4800   1599956143  g507sg9   t3_irnlz8  t3_irnlz8         False  \n",
       "4801   1599955741  g506ikx   t3_irnlz8  t3_irnlz8         False  \n",
       "4802   1599955546  g5061yy   t3_irnlz8  t3_irnlz8         False  \n",
       "4803   1599955330  g505ffz   t3_irnlz8  t3_irnlz8         False  \n",
       "\n",
       "[4804 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lite_cdf = comm_df[['author', 'score', 'body', 'stickied', 'created_utc', 'id', 'parent_id', 'link_id', 'is_submitter']]\n",
    "lite_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>stickied</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>is_submitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Budgie2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Really excited to find this one--never heard o...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600809663</td>\n",
       "      <td>g696zi1</td>\n",
       "      <td>t1_g66cqnr</td>\n",
       "      <td>t3_ix7ua1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fahrenheitisretarded</td>\n",
       "      <td>1</td>\n",
       "      <td>Great suggestion. Forgot about that film entir...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600808248</td>\n",
       "      <td>g6946y3</td>\n",
       "      <td>t1_g66cqnr</td>\n",
       "      <td>t3_ix7ua1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexander_The_Based</td>\n",
       "      <td>1</td>\n",
       "      <td>gonna watch pirates band of misfits. i can't b...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600808239</td>\n",
       "      <td>g6946av</td>\n",
       "      <td>t1_g66xbjq</td>\n",
       "      <td>t3_iwlb0z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nofuchsgiven1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes it was.</td>\n",
       "      <td>False</td>\n",
       "      <td>1600806958</td>\n",
       "      <td>g691l03</td>\n",
       "      <td>t1_g67nmff</td>\n",
       "      <td>t3_ix7ua1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Truthisnotallowed</td>\n",
       "      <td>1</td>\n",
       "      <td>If you enjoy dark comedies you might also like...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600801282</td>\n",
       "      <td>g68q343</td>\n",
       "      <td>t1_g67h8ld</td>\n",
       "      <td>t3_ixcr5j</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>MammothEase</td>\n",
       "      <td>1</td>\n",
       "      <td>It's so good, it feels so real.</td>\n",
       "      <td>False</td>\n",
       "      <td>1599964025</td>\n",
       "      <td>g50xvkk</td>\n",
       "      <td>t1_g50uo6l</td>\n",
       "      <td>t3_iro0jk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>GoGoPowerPlay</td>\n",
       "      <td>3</td>\n",
       "      <td>Not the OP, but just looked up Ordinary People...</td>\n",
       "      <td>False</td>\n",
       "      <td>1599963077</td>\n",
       "      <td>g50uo6l</td>\n",
       "      <td>t1_g50hmkw</td>\n",
       "      <td>t3_iro0jk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>jryan102</td>\n",
       "      <td>2</td>\n",
       "      <td>Lol I was about to watch that</td>\n",
       "      <td>False</td>\n",
       "      <td>1599959411</td>\n",
       "      <td>g50iacm</td>\n",
       "      <td>t1_g50i62y</td>\n",
       "      <td>t3_iroswy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>toxic_pantaloons</td>\n",
       "      <td>3</td>\n",
       "      <td>Yeah that's one uh, first encounter that's har...</td>\n",
       "      <td>False</td>\n",
       "      <td>1599956621</td>\n",
       "      <td>g509bbv</td>\n",
       "      <td>t1_g508eqa</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>xUserNameRedactedx</td>\n",
       "      <td>1</td>\n",
       "      <td>I second Event Horizon, I actually came here t...</td>\n",
       "      <td>False</td>\n",
       "      <td>1599956383</td>\n",
       "      <td>g508eqa</td>\n",
       "      <td>t1_g507sg9</td>\n",
       "      <td>t3_irnlz8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author  score  \\\n",
       "2               Budgie2018      1   \n",
       "3     fahrenheitisretarded      1   \n",
       "4      Alexander_The_Based      1   \n",
       "5            nofuchsgiven1      1   \n",
       "7        Truthisnotallowed      1   \n",
       "...                    ...    ...   \n",
       "4772           MammothEase      1   \n",
       "4777         GoGoPowerPlay      3   \n",
       "4786              jryan102      2   \n",
       "4795      toxic_pantaloons      3   \n",
       "4797    xUserNameRedactedx      1   \n",
       "\n",
       "                                                   body  stickied  \\\n",
       "2     Really excited to find this one--never heard o...     False   \n",
       "3     Great suggestion. Forgot about that film entir...     False   \n",
       "4     gonna watch pirates band of misfits. i can't b...     False   \n",
       "5                                           Yes it was.     False   \n",
       "7     If you enjoy dark comedies you might also like...     False   \n",
       "...                                                 ...       ...   \n",
       "4772                    It's so good, it feels so real.     False   \n",
       "4777  Not the OP, but just looked up Ordinary People...     False   \n",
       "4786                      Lol I was about to watch that     False   \n",
       "4795  Yeah that's one uh, first encounter that's har...     False   \n",
       "4797  I second Event Horizon, I actually came here t...     False   \n",
       "\n",
       "      created_utc       id   parent_id    link_id  is_submitter  \n",
       "2      1600809663  g696zi1  t1_g66cqnr  t3_ix7ua1          True  \n",
       "3      1600808248  g6946y3  t1_g66cqnr  t3_ix7ua1         False  \n",
       "4      1600808239  g6946av  t1_g66xbjq  t3_iwlb0z          True  \n",
       "5      1600806958  g691l03  t1_g67nmff  t3_ix7ua1         False  \n",
       "7      1600801282  g68q343  t1_g67h8ld  t3_ixcr5j         False  \n",
       "...           ...      ...         ...        ...           ...  \n",
       "4772   1599964025  g50xvkk  t1_g50uo6l  t3_iro0jk         False  \n",
       "4777   1599963077  g50uo6l  t1_g50hmkw  t3_iro0jk         False  \n",
       "4786   1599959411  g50iacm  t1_g50i62y  t3_iroswy          True  \n",
       "4795   1599956621  g509bbv  t1_g508eqa  t3_irnlz8         False  \n",
       "4797   1599956383  g508eqa  t1_g507sg9  t3_irnlz8         False  \n",
       "\n",
       "[1482 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lite_cdf[lite_cdf['parent_id'] != lite_cdf['link_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_cdf.to_csv('./movies_data/comments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
