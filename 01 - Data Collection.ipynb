{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import timezone\n",
    "import time\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "url_com = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "res = requests.get(url, params = {'subreddit' : 'moviesuggestions'})\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function created for Project 3, modified for better functionality and capstone project needs\n",
    "\n",
    "def get_sub_df(sub_name, num_to_pull, start_utc = None, min_comments = 0, drop_removed = True):\n",
    "    #Returns a dataframe containing num_to_pull submissions from the specified subreddit\n",
    "    #Dataframe has ID, Title, selftext and num_comments\n",
    "    \n",
    "    post_count = 0    #Keeps track of how many posts have been pulled\n",
    "    data = []         #Holds all the data to create the DF after the while loop\n",
    "    \n",
    "    res_count = 0     #for debugging\n",
    "    \n",
    "    if start_utc == None:\n",
    "        start_utc = int(datetime.now(timezone.utc).timestamp()) #If the start timestamp isn't specified, use the current time\n",
    "        \n",
    "    min_comment_count = '>' + str(min_comments-1) #paramater to select only submissions with comments greater than the number specified\n",
    "    \n",
    "    timer = 0 \n",
    "    \n",
    "    while post_count < num_to_pull:\n",
    "        #To make sure to get the specific number pulled, check to see if the remaining count is less than 100, if not, just get 100\n",
    "        if (num_to_pull - post_count) < 100:\n",
    "            get_size = (num_to_pull - post_count)\n",
    "        else:\n",
    "            get_size = 100\n",
    "            \n",
    "        timer = time.time() #Timer to avoid 429 codes from making too many requests\n",
    "        \n",
    "        res = requests.get(url, params = {'subreddit' : sub_name, 'size' : get_size, 'before' : start_utc, 'num_comments' : min_comment_count})\n",
    "        res_count += 1\n",
    "        \n",
    "        clear_output(wait=True) #reference: https://stackoverflow.com/a/24818304\n",
    "        \n",
    "        print(f'{100 * post_count/num_to_pull}%')\n",
    "        \n",
    "        # Wait for ONE second, but in 0.1s increments (saves time because the request may have taken >0.1s)\n",
    "        # This shouldn't ever come close to exceeding the limit of 200 requests/minute\n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            print(f'Status Code: {res.status_code}')\n",
    "            print(res_count)\n",
    "            return None\n",
    "            \n",
    "        new_data = res.json()['data']\n",
    "            \n",
    "        data.extend(new_data)\n",
    "        \n",
    "        post_count += 100 #not a problem to go over num_to_pull\n",
    "        \n",
    "        if post_count < num_to_pull:\n",
    "            try:\n",
    "                #This is the starting point for grabbing more posts\n",
    "                start_utc = new_data[-1]['created_utc']\n",
    "            except:\n",
    "                #If that doesn't work, try to find out what went wrong:\n",
    "                print(\"Failed to get UTC of last Post. Printing list element that caused failure.\")\n",
    "                try:\n",
    "                    post_count = num_to_pull\n",
    "                    print(new_data[-1])\n",
    "                except:\n",
    "                    print(\"Printing last list element failed.\")\n",
    "    \n",
    "    print(res_count)\n",
    "    \n",
    "    columns_for_df = ['id', 'title', 'selftext', 'removed_by_category', 'created_utc', 'num_comments', 'link_flair_css_class']\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    #select the columns, but only if they exist in the dataframe - the res won't return data when there are 0 non-null values\n",
    "    df = df[df.columns & columns_for_df]\n",
    "    \n",
    "    #Filter out submissions that have been removed. Could result in small samples for heavily moderated forums, so there is the option to keep them in.\n",
    "    if drop_removed and 'removed_by_category' in df.columns:\n",
    "        df = df[df['removed_by_category'].isna()]\n",
    "    \n",
    "    #Drop this column, it is no longer needed\n",
    "    if 'removed_by_category' in df.columns:\n",
    "        df.drop(columns = 'removed_by_category', inplace = True)\n",
    "    \n",
    "    #Convert timestamps to datetimes\n",
    "    df['created_utc'] = df['created_utc'].apply(datetime.fromtimestamp)    \n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(df):\n",
    "    #function to get dictionary from json data - using submission id numbers from the passed dataframe\n",
    "    #This function should work on any size df*, but may take a looong time if there are a lot of comments to get \n",
    "    # - if new comments are being made on the submissions, this function might not get all the comments\n",
    "    #  * unless there is a limit in the API on how many ids can be passed\n",
    "    \n",
    "    #First, get a list of id's from submissions in the dataframe: \n",
    "    \n",
    "    id_string = ''\n",
    "    \n",
    "    for i in df['id']:\n",
    "        id_string += i + ', ' #needs to be formated like: 'id1234, id1235, id1236'\n",
    "        \n",
    "    id_string = id_string[:-2] #drop the last ', '\n",
    "    \n",
    "    #Get the first batch of data and create the list that will ultimately be returned\n",
    "    com_res = requests.get(url_com, params = {'link_id' : id_string, 'size' : 500})\n",
    "    com_data = com_res.json()['data']\n",
    "    \n",
    "    #Check to make sure that the request worked:\n",
    "    if com_res.status_code != 200:\n",
    "        print(f'Status code: {com_res.status_code}')\n",
    "        return None\n",
    "    \n",
    "    #This is the goal - the number of comments we want to end up with (ideally)\n",
    "    num_comments = df['num_comments'].sum() \n",
    "    \n",
    "    last_length = -1\n",
    "    comment_count = 0\n",
    "    timer = 0\n",
    "    \n",
    "    res_counter = 0\n",
    "    \n",
    "    # Handling the case when there are no comments to get:\n",
    "    if len(com_data) == 0:\n",
    "        return com_data\n",
    "    \n",
    "    while (len(com_data) < num_comments) & (last_length != len(com_data)):\n",
    "        #This makes sure that the while loop doesn't continue forever if something goes wrong\n",
    "        last_length = len(com_data)\n",
    "        \n",
    "        try:\n",
    "            #This is the starting point for grabbing more comments\n",
    "            last_comment_utc = com_data[-1]['created_utc'] \n",
    "        except:\n",
    "            print(\"Failed to get UTC of last comment. Printing list element that caused failure.\")\n",
    "            print(com_data[-1])\n",
    "        \n",
    "        timer = time.time()\n",
    "        \n",
    "        new_res = requests.get(url_com, params = {'link_id' : id_string,\n",
    "                                                  'size' : 500,\n",
    "                                                  'before' : last_comment_utc,\n",
    "                                                  'limit' : 500})\n",
    "        \n",
    "        res_counter += 1\n",
    "        \n",
    "        comment_count += 500\n",
    "        \n",
    "        print(f'{100 * comment_count/num_comments}%')\n",
    "        \n",
    "        \n",
    "        while time.time() < (timer + 1):\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if new_res.status_code == 200:\n",
    "            \n",
    "            new_data = new_res.json()['data']\n",
    "            \n",
    "            for new_comment in new_data:\n",
    "                com_data.append(new_comment)\n",
    "                \n",
    "        else:\n",
    "            print(f'Problem when pulling new comments: Code {new_res.status_code}')\n",
    "            \n",
    "    print(res_counter)\n",
    "            \n",
    "    return com_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_comments(com_data, df):\n",
    "    #Take comment data ( .json()['data'] ) and make a new column for the dataframe with the comment texts\n",
    "    \n",
    "    df_c = df.copy() #make a copy of the df, just to be safe/explicit. This copy is what is returned by the function.\n",
    "\n",
    "    #Make a zip opject with submission ids and comment text\n",
    "    com_zip = zip([com_data[i]['link_id'][-6:] for i in range(len(com_data))], [com_data[i]['body'] for i in range(len(com_data))])\n",
    "\n",
    "    # create a list of empty lists and make that list the new column\n",
    "    df_c['comments'] = [[] for _ in range(len(df_c))]\n",
    "    \n",
    "    # how many comments are assigned to each row in the dataframe\n",
    "    assignments = np.zeros_like(df_c['num_comments'])\n",
    "\n",
    "    #List of ids, to check if the comment's submission id is in the dataframe\n",
    "    id_list = df_c['id'].values\n",
    "\n",
    "    #counts the total number of comments that can't be assigned to a row\n",
    "    unassigned = 0\n",
    "\n",
    "    #Loop through the zip object, appending comments to the correct row on the 'comments' columns created above, then add 1 to assignment list (to be column later)\n",
    "    for idx, com in com_zip:\n",
    "        if idx in id_list:\n",
    "            df_c[df_c['id'] == idx]['comments'].item().append(com)\n",
    "            assignments[df_c[df_c['id'] == idx].index.item()] += 1\n",
    "        else:\n",
    "            unassigned += 1\n",
    "\n",
    "    if(unassigned > 0):\n",
    "        print(f'There are {unassigned} comments that could not be assigned to a submission!')\n",
    "    \n",
    "    df_c['assigned_comments'] = assignments\n",
    "    \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_assign_comments(df):\n",
    "    #This function grabs comments in chunks and assigns them to the submissions\n",
    "    #\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    comment_data = []\n",
    "    \n",
    "    total_length = df_copy.shape[0]\n",
    "    \n",
    "    chunk = 0\n",
    "    chunk_size = 25\n",
    "    \n",
    "    while chunk * chunk_size < total_length:\n",
    "        start_row = chunk * chunk_size\n",
    "        end_row = (chunk + 1) * chunk_size\n",
    "        \n",
    "        if end_row < total_length:\n",
    "            comment_data += get_comments(df_copy[start_row : end_row + 1])\n",
    "        else:\n",
    "            comment_data += get_comments(df_copy[start_row :])\n",
    "            \n",
    "        chunk += 1\n",
    "    \n",
    "    df_copy = assign_comments(comment_data, df_copy)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_text(sub_name, number = 10_000, start_time = None):\n",
    "    if sub_name + '_data.csv' in os.listdir('./data'):\n",
    "        print(f\"That data ({sub_name}) is already in the data folder. Delete the file if you want to get the data again.\")\n",
    "        return None\n",
    "    else:\n",
    "        df = get_sub_df(sub_name, number, start_utc = start_time)\n",
    "        #df = get_and_assign_comments(df)\n",
    "        # -----> Will be moved to new DF and CSV, assignment will be handled differently\n",
    "        df.to_csv('./data/' + sub_name + '_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now(timezone.utc)\n",
    "yesterday = today - timedelta(days = 1)\n",
    "yesterday_timestamp = int(datetime.timestamp(yesterday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "1\n",
      "133.33333333333334%\n",
      "1\n",
      "134.04825737265415%\n",
      "268.0965147453083%\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "get_titles_text('moviesuggestions', number = 500, start_time = yesterday_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/moviesuggestions_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.73841554559043%\n",
      "149.47683109118086%\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "com_data = get_comments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "request    0.861111\n",
       "suggest    0.138889\n",
       "Name: link_flair_css_class, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['link_flair_css_class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>252.402985</td>\n",
       "      <td>21.902985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>230.046512</td>\n",
       "      <td>10.209302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index  num_comments\n",
       "link_flair_css_class                          \n",
       "request               252.402985     21.902985\n",
       "suggest               230.046512     10.209302"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by = 'link_flair_css_class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'created_utc', 'id', 'link_flair_css_class', 'num_comments',\n",
       "       'selftext', 'title', 'comments', 'assigned_comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More work:\n",
    "\n",
    "Currently the csv has all the comments in a single cell.\n",
    "\n",
    "This is a problem because they are saved as one long string, and without any data such as author, score, nest level, etc., which will likely be important as this project goes on. (such as removing negative-score comments from consideration, or collecting data from helpful bots)\n",
    "\n",
    "I will need to create a new database for comments and use that alongside the title/text data. Keeping them together in the same csv won't work for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = pd.DataFrame(com_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'approved_at_utc', 'associated_award', 'author',\n",
       "       'author_cakeday', 'author_flair_background_color',\n",
       "       'author_flair_css_class', 'author_flair_richtext',\n",
       "       'author_flair_template_id', 'author_flair_text',\n",
       "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
       "       'author_patreon_flair', 'author_premium', 'awarders', 'banned_at_utc',\n",
       "       'body', 'can_mod_post', 'collapsed', 'collapsed_because_crowd_control',\n",
       "       'collapsed_reason', 'comment_type', 'created_utc', 'distinguished',\n",
       "       'edited', 'gildings', 'id', 'is_submitter', 'link_id', 'locked',\n",
       "       'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score',\n",
       "       'send_replies', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'top_awarded_type', 'total_awards_received', 'treatment_tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>stickied</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>is_submitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Truthisnotallowed</td>\n",
       "      <td>1</td>\n",
       "      <td>[3 Idiots](https://www.imdb.com/title/tt118704...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600654829</td>\n",
       "      <td>g624ur4</td>\n",
       "      <td>t3_iw3qs3</td>\n",
       "      <td>t3_iw3qs3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Truthisnotallowed</td>\n",
       "      <td>1</td>\n",
       "      <td>[Hobson's Choice](https://www.imdb.com/title/t...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600654755</td>\n",
       "      <td>g624q0m</td>\n",
       "      <td>t3_iw0sit</td>\n",
       "      <td>t3_iw0sit</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Truthisnotallowed</td>\n",
       "      <td>1</td>\n",
       "      <td>[Romancing The Stone](https://www.imdb.com/tit...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600654536</td>\n",
       "      <td>g624bq0</td>\n",
       "      <td>t3_ivx5cb</td>\n",
       "      <td>t3_ivx5cb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Truthisnotallowed</td>\n",
       "      <td>1</td>\n",
       "      <td>[Secret Superstar](https://www.imdb.com/title/...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600654416</td>\n",
       "      <td>g6243te</td>\n",
       "      <td>t3_ivw84x</td>\n",
       "      <td>t3_ivw84x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Truthisnotallowed</td>\n",
       "      <td>1</td>\n",
       "      <td>[3 Idiots](https://www.imdb.com/title/tt118704...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600654274</td>\n",
       "      <td>g623uf6</td>\n",
       "      <td>t3_ivv7ap</td>\n",
       "      <td>t3_ivv7ap</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>iBroly</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks! I've seen a few of these but I'll give...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600494010</td>\n",
       "      <td>g5sdf0q</td>\n",
       "      <td>t1_g5sd2h2</td>\n",
       "      <td>t3_ivm78y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Sirius_Space</td>\n",
       "      <td>2</td>\n",
       "      <td>You looking for those teen dystopian films ? \\...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600493717</td>\n",
       "      <td>g5sd2h2</td>\n",
       "      <td>t3_ivm78y</td>\n",
       "      <td>t3_ivm78y</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>TheNostromo_87</td>\n",
       "      <td>151</td>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>False</td>\n",
       "      <td>1600493154</td>\n",
       "      <td>g5sceqb</td>\n",
       "      <td>t3_ivmjg0</td>\n",
       "      <td>t3_ivmjg0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>False</td>\n",
       "      <td>1600491640</td>\n",
       "      <td>g5sajdn</td>\n",
       "      <td>t3_ivm78y</td>\n",
       "      <td>t3_ivm78y</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1</td>\n",
       "      <td>[Coming of Age](https://www.reddit.com/r/Movie...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600488432</td>\n",
       "      <td>g5s5hyb</td>\n",
       "      <td>t3_ivlgzz</td>\n",
       "      <td>t3_ivlgzz</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author  score  \\\n",
       "0    Truthisnotallowed      1   \n",
       "1    Truthisnotallowed      1   \n",
       "2    Truthisnotallowed      1   \n",
       "3    Truthisnotallowed      1   \n",
       "4    Truthisnotallowed      1   \n",
       "..                 ...    ...   \n",
       "780             iBroly      1   \n",
       "781       Sirius_Space      2   \n",
       "782     TheNostromo_87    151   \n",
       "783          [deleted]      1   \n",
       "784      AutoModerator      1   \n",
       "\n",
       "                                                  body  stickied  created_utc  \\\n",
       "0    [3 Idiots](https://www.imdb.com/title/tt118704...     False   1600654829   \n",
       "1    [Hobson's Choice](https://www.imdb.com/title/t...     False   1600654755   \n",
       "2    [Romancing The Stone](https://www.imdb.com/tit...     False   1600654536   \n",
       "3    [Secret Superstar](https://www.imdb.com/title/...     False   1600654416   \n",
       "4    [3 Idiots](https://www.imdb.com/title/tt118704...     False   1600654274   \n",
       "..                                                 ...       ...          ...   \n",
       "780  Thanks! I've seen a few of these but I'll give...     False   1600494010   \n",
       "781  You looking for those teen dystopian films ? \\...     False   1600493717   \n",
       "782                           The Silence of the Lambs     False   1600493154   \n",
       "783                                          [removed]     False   1600491640   \n",
       "784  [Coming of Age](https://www.reddit.com/r/Movie...     False   1600488432   \n",
       "\n",
       "          id   parent_id    link_id  is_submitter  \n",
       "0    g624ur4   t3_iw3qs3  t3_iw3qs3         False  \n",
       "1    g624q0m   t3_iw0sit  t3_iw0sit         False  \n",
       "2    g624bq0   t3_ivx5cb  t3_ivx5cb         False  \n",
       "3    g6243te   t3_ivw84x  t3_ivw84x         False  \n",
       "4    g623uf6   t3_ivv7ap  t3_ivv7ap         False  \n",
       "..       ...         ...        ...           ...  \n",
       "780  g5sdf0q  t1_g5sd2h2  t3_ivm78y          True  \n",
       "781  g5sd2h2   t3_ivm78y  t3_ivm78y         False  \n",
       "782  g5sceqb   t3_ivmjg0  t3_ivmjg0         False  \n",
       "783  g5sajdn   t3_ivm78y  t3_ivm78y         False  \n",
       "784  g5s5hyb   t3_ivlgzz  t3_ivlgzz         False  \n",
       "\n",
       "[785 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lite_cdf = comm_df[['author', 'score', 'body', 'stickied', 'created_utc', 'id', 'parent_id', 'link_id', 'is_submitter']]\n",
    "lite_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>stickied</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>is_submitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reddit-Book-Bot</td>\n",
       "      <td>1</td>\n",
       "      <td>Beep. Boop. I'm a robot.\\nHere's a copy of \\n\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600654086</td>\n",
       "      <td>g623hae</td>\n",
       "      <td>t1_g623gl8</td>\n",
       "      <td>t3_ivqiph</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>betsy_blair_fan</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, all this is true, Hedwig allthesame is a...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600651185</td>\n",
       "      <td>g61yhr7</td>\n",
       "      <td>t1_g5xvsjy</td>\n",
       "      <td>t3_ivt18o</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jupiterkansas</td>\n",
       "      <td>1</td>\n",
       "      <td>so nothing to contribute. thanks for your time.</td>\n",
       "      <td>False</td>\n",
       "      <td>1600645425</td>\n",
       "      <td>g61ojxm</td>\n",
       "      <td>t1_g61nz6a</td>\n",
       "      <td>t3_ivxpui</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hereiamtosavetheday_</td>\n",
       "      <td>1</td>\n",
       "      <td>You're like a dog with a rubber bone, insistin...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600645082</td>\n",
       "      <td>g61nz6a</td>\n",
       "      <td>t1_g61ns2l</td>\n",
       "      <td>t3_ivxpui</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jupiterkansas</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow, now you're being childish. \\n\\nEver since...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600644961</td>\n",
       "      <td>g61ns2l</td>\n",
       "      <td>t1_g61iyg3</td>\n",
       "      <td>t3_ivxpui</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>ArtAngelBlonde</td>\n",
       "      <td>12</td>\n",
       "      <td>Definitely the GOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>1600513963</td>\n",
       "      <td>g5sxtlu</td>\n",
       "      <td>t1_g5siz8o</td>\n",
       "      <td>t3_ivmjg0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>blacky-o-hare</td>\n",
       "      <td>1</td>\n",
       "      <td>Yea I liked it have you seen what lies beneath?</td>\n",
       "      <td>False</td>\n",
       "      <td>1600504986</td>\n",
       "      <td>g5spsvw</td>\n",
       "      <td>t1_g5spqjp</td>\n",
       "      <td>t3_ivoqnu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>a03b</td>\n",
       "      <td>2</td>\n",
       "      <td>Seen. What a masterpiece that was. Now that I ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600504913</td>\n",
       "      <td>g5spqjp</td>\n",
       "      <td>t1_g5splek</td>\n",
       "      <td>t3_ivoqnu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Jatef</td>\n",
       "      <td>37</td>\n",
       "      <td>LMAO I love that this was the only comment omg.</td>\n",
       "      <td>False</td>\n",
       "      <td>1600494182</td>\n",
       "      <td>g5sdmak</td>\n",
       "      <td>t1_g5sceqb</td>\n",
       "      <td>t3_ivmjg0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>iBroly</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks! I've seen a few of these but I'll give...</td>\n",
       "      <td>False</td>\n",
       "      <td>1600494010</td>\n",
       "      <td>g5sdf0q</td>\n",
       "      <td>t1_g5sd2h2</td>\n",
       "      <td>t3_ivm78y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author  score  \\\n",
       "6         Reddit-Book-Bot      1   \n",
       "9         betsy_blair_fan      1   \n",
       "10          jupiterkansas      1   \n",
       "11   hereiamtosavetheday_      1   \n",
       "13          jupiterkansas      1   \n",
       "..                    ...    ...   \n",
       "731        ArtAngelBlonde     12   \n",
       "763         blacky-o-hare      1   \n",
       "764                  a03b      2   \n",
       "779                 Jatef     37   \n",
       "780                iBroly      1   \n",
       "\n",
       "                                                  body  stickied  created_utc  \\\n",
       "6    Beep. Boop. I'm a robot.\\nHere's a copy of \\n\\...     False   1600654086   \n",
       "9    Yeah, all this is true, Hedwig allthesame is a...     False   1600651185   \n",
       "10     so nothing to contribute. thanks for your time.     False   1600645425   \n",
       "11   You're like a dog with a rubber bone, insistin...     False   1600645082   \n",
       "13   Wow, now you're being childish. \\n\\nEver since...     False   1600644961   \n",
       "..                                                 ...       ...          ...   \n",
       "731                                Definitely the GOAT     False   1600513963   \n",
       "763    Yea I liked it have you seen what lies beneath?     False   1600504986   \n",
       "764  Seen. What a masterpiece that was. Now that I ...     False   1600504913   \n",
       "779    LMAO I love that this was the only comment omg.     False   1600494182   \n",
       "780  Thanks! I've seen a few of these but I'll give...     False   1600494010   \n",
       "\n",
       "          id   parent_id    link_id  is_submitter  \n",
       "6    g623hae  t1_g623gl8  t3_ivqiph         False  \n",
       "9    g61yhr7  t1_g5xvsjy  t3_ivt18o         False  \n",
       "10   g61ojxm  t1_g61nz6a  t3_ivxpui         False  \n",
       "11   g61nz6a  t1_g61ns2l  t3_ivxpui         False  \n",
       "13   g61ns2l  t1_g61iyg3  t3_ivxpui         False  \n",
       "..       ...         ...        ...           ...  \n",
       "731  g5sxtlu  t1_g5siz8o  t3_ivmjg0         False  \n",
       "763  g5spsvw  t1_g5spqjp  t3_ivoqnu         False  \n",
       "764  g5spqjp  t1_g5splek  t3_ivoqnu          True  \n",
       "779  g5sdmak  t1_g5sceqb  t3_ivmjg0         False  \n",
       "780  g5sdf0q  t1_g5sd2h2  t3_ivm78y          True  \n",
       "\n",
       "[214 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lite_cdf[lite_cdf['parent_id'] != lite_cdf['link_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_cdf.to_csv('./movies_data/comments_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
