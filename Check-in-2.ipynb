{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Check-in 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project:\n",
    "\n",
    "**NLP Recommender System for Movies** (Idea #1 from Check-in 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "Recommender systems for media often can't take into account important factors like the question, \"what do you actually feel like watching right now?\" The solution is to build a recommender system that asks for a free-form text input describing a person's momentary preferences, and recommends movies to watch based on that input. F1 scores will be used to evaluate and improve performance (comparing machine recommendations to human recommendations), as the ranking of the results will not be evaluated since the user's true preferences cannot be known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods and Goals:\n",
    "\n",
    "Data will be collected from reddit, specifically the subreddit /r/moviesuggestions. Using the posts in this request-suggestion format, I will us NLP (spacy) to identify and tag movie titles from a list of films and build a database that connects request text to movie suggestions.\n",
    "\n",
    "From here there are several possible apporaches for recommenders. A relatively simple approach utilizing important words in the corpus is likely the first step. This would be a content-based recommender system. For some posts it may be possible to combine this with a collaborative recommender if the user inputs movie titles as a part of their request. Other possibilites to explore include sentiment analysis and document similarity. This multifaceted system would need to decide which models to use and how to weight them, for example, only applying sentiment analyisis recommendations on documents that exhibit strong sentiments.\n",
    "\n",
    "Despite the complexity above, a working system meeting one or two of the above goals should be achievable with time to build on the system and experiment. More complex NLP tools will be explored if the above goals are all achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data:\n",
    "\n",
    "Based on early EDA using recent submissions to /r/moviesuggestions, it is likely that there are at least 10,000 submissions that can be used for this system. Currently the forum generally sees over 30 submissions per day, with 85% of those being requests for movies to watch. Recently these request posts average about 22 replies, though not all replies will contain any recommendations. I will assume that posts with negative scores are bad recommendations and not inlcude those in the data.\n",
    "\n",
    "Currently, more work needs to be done, as the comments will require their own dataframe with comment-specific data (more than just text). These can be matched  to the submission text/self-text dataframe using the submission's 'id' value.\n",
    "\n",
    "With this data source, there may be a strong tendency for the recommender to default to very popular movies for most input documents. I will have to research how to deal with that, if it is a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information and analysis of this subreddit can be found here:\n",
    "\n",
    "https://subredditstats.com/r/moviesuggestions\n",
    "\n",
    "This site has graphs and estimates of posts and comments per day, as well the history of posting on this subreddit, such as a very mysterious spike in activity beginning in April, 2020, what could that be about? Were we all just sitting around watching movies? Yes, we were.\n",
    "\n",
    "We can see that for the past year and a half, activity has been generally averaged 30+ posts per day and 300+ comments per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>assigned_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-15 19:28:59</td>\n",
       "      <td>itl4by</td>\n",
       "      <td>request</td>\n",
       "      <td>13</td>\n",
       "      <td>Looking for movie that  involveds the hunting ...</td>\n",
       "      <td>Similar to The Purge series or 31</td>\n",
       "      <td>['Hush (2016)', '\"They Live-1988\", does it cou...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-09-15 18:40:25</td>\n",
       "      <td>itkci7</td>\n",
       "      <td>request</td>\n",
       "      <td>11</td>\n",
       "      <td>I am a fan of adult comedies like the American...</td>\n",
       "      <td>Adult Comedies?</td>\n",
       "      <td>['can’t be judging movies off of trailers smh'...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-09-15 18:16:15</td>\n",
       "      <td>itjyza</td>\n",
       "      <td>request</td>\n",
       "      <td>11</td>\n",
       "      <td>Could be any genre. Im looking for the movies ...</td>\n",
       "      <td>Cozy vibe movies</td>\n",
       "      <td>['Time Bandits', 'The Ninth Gate\\n\\nCastaway\\n...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-15 17:37:13</td>\n",
       "      <td>itjc7y</td>\n",
       "      <td>request</td>\n",
       "      <td>11</td>\n",
       "      <td>I’m 15, and I really love movies (plus I want ...</td>\n",
       "      <td>Movie(s) that you think everyone should watch,...</td>\n",
       "      <td>['Tokyo Drifter\\n\\nSympathy for Lady Vengeance...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-15 15:28:09</td>\n",
       "      <td>itgyzn</td>\n",
       "      <td>suggest</td>\n",
       "      <td>1</td>\n",
       "      <td>It's an amazing movie. Nor many people have he...</td>\n",
       "      <td>Marrowbone</td>\n",
       "      <td>['Your Post was Removed because [Marrowbone] h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          created_utc      id link_flair_css_class  num_comments  \\\n",
       "0      0  2020-09-15 19:28:59  itl4by              request            13   \n",
       "1      2  2020-09-15 18:40:25  itkci7              request            11   \n",
       "2      4  2020-09-15 18:16:15  itjyza              request            11   \n",
       "3      5  2020-09-15 17:37:13  itjc7y              request            11   \n",
       "4      7  2020-09-15 15:28:09  itgyzn              suggest             1   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  Looking for movie that  involveds the hunting ...   \n",
       "1  I am a fan of adult comedies like the American...   \n",
       "2  Could be any genre. Im looking for the movies ...   \n",
       "3  I’m 15, and I really love movies (plus I want ...   \n",
       "4  It's an amazing movie. Nor many people have he...   \n",
       "\n",
       "                                               title  \\\n",
       "0                  Similar to The Purge series or 31   \n",
       "1                                    Adult Comedies?   \n",
       "2                                   Cozy vibe movies   \n",
       "3  Movie(s) that you think everyone should watch,...   \n",
       "4                                         Marrowbone   \n",
       "\n",
       "                                            comments  assigned_comments  \n",
       "0  ['Hush (2016)', '\"They Live-1988\", does it cou...                 12  \n",
       "1  ['can’t be judging movies off of trailers smh'...                 11  \n",
       "2  ['Time Bandits', 'The Ninth Gate\\n\\nCastaway\\n...                 11  \n",
       "3  ['Tokyo Drifter\\n\\nSympathy for Lady Vengeance...                 11  \n",
       "4  ['Your Post was Removed because [Marrowbone] h...                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/moviesuggestions_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Currently, the comments are not in an easily useable format and lack some useful information. For these reasons, I will build a new database for just the comments, to facilitate filtering and nlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "request    0.861736\n",
       "suggest    0.138264\n",
       "Name: link_flair_css_class, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['link_flair_css_class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 86% of the latest posts were requests, rather than unsolicited suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 500 posts were scaped with the API but only 316 were not removed (by moderators, administrators, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If these numbers hold as more data is gathered, the past year and half should yield over 8,000 useable posts. If there are 30 posts per day, and (316/500 =) 63.2% of posts are not removed, and 85% of posts are requests, then about 8,800 posts will be useable from the last 18 months. Since I don't have any information about posting activity before that time, I cannot estimate how much more data can be obtained, though it is likely a considerable amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>assigned_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>252.402985</td>\n",
       "      <td>22.063433</td>\n",
       "      <td>20.753731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>230.046512</td>\n",
       "      <td>10.209302</td>\n",
       "      <td>9.255814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index  num_comments  assigned_comments\n",
       "link_flair_css_class                                             \n",
       "request               252.402985     22.063433          20.753731\n",
       "suggest               230.046512     10.209302           9.255814"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by = 'link_flair_css_class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recently, requests for recommendations recieve an average of 21 responses, but I don't yet have information about how many recommendations are being made. Comments might contain no recommendations, or several,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "While developing the system, the data will be split into training and testing sets. Recommendations made by the system will be compared to actual recommendations to find precision, sensitivity, and f1 scores for each recommendation. Any metric that evaluates true negatives (movies that were not recommended by either human or computer) will always have an extremely high score, since the vast majority movies will fall into this category for any given document. There will be some problems here with variation in number of responses, so some limitations (such as compare the top x recommendations) may be necessary when evaluating the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
